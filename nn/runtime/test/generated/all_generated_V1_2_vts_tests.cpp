// DO NOT EDIT;
// Generated by ml/nn/runtime/test/specs/generate_vts_test.sh

namespace argmax_1_float {
std::vector<MixedTypedExample> examples = {
// Generated argmax_1_float test
#include "examples/argmax_1_float.example.cpp"
};
// Generated model constructor
#include "vts_models/argmax_1_float.model.cpp"
} // namespace argmax_1_float
TEST_F(NeuralnetworksHidlTest, argmax_1_float) {
    generated_tests::Execute(device,
                             argmax_1_float::createTestModel,
                             argmax_1_float::is_ignored,
                             argmax_1_float::examples);
}

namespace argmax_1_float_relaxed {
std::vector<MixedTypedExample> examples = {
// Generated argmax_1_float_relaxed test
#include "examples/argmax_1_float_relaxed.example.cpp"
};
// Generated model constructor
#include "vts_models/argmax_1_float_relaxed.model.cpp"
} // namespace argmax_1_float_relaxed
TEST_F(NeuralnetworksHidlTest, argmax_1_float_relaxed) {
    generated_tests::Execute(device,
                             argmax_1_float_relaxed::createTestModel,
                             argmax_1_float_relaxed::is_ignored,
                             argmax_1_float_relaxed::examples);
}

namespace argmax_1_int32 {
std::vector<MixedTypedExample> examples = {
// Generated argmax_1_int32 test
#include "examples/argmax_1_int32.example.cpp"
};
// Generated model constructor
#include "vts_models/argmax_1_int32.model.cpp"
} // namespace argmax_1_int32
TEST_F(NeuralnetworksHidlTest, argmax_1_int32) {
    generated_tests::Execute(device,
                             argmax_1_int32::createTestModel,
                             argmax_1_int32::is_ignored,
                             argmax_1_int32::examples);
}

namespace argmax_1_quant8 {
std::vector<MixedTypedExample> examples = {
// Generated argmax_1_quant8 test
#include "examples/argmax_1_quant8.example.cpp"
};
// Generated model constructor
#include "vts_models/argmax_1_quant8.model.cpp"
} // namespace argmax_1_quant8
TEST_F(NeuralnetworksHidlTest, argmax_1_quant8) {
    generated_tests::Execute(device,
                             argmax_1_quant8::createTestModel,
                             argmax_1_quant8::is_ignored,
                             argmax_1_quant8::examples);
}

namespace argmax_2_float {
std::vector<MixedTypedExample> examples = {
// Generated argmax_2_float test
#include "examples/argmax_2_float.example.cpp"
};
// Generated model constructor
#include "vts_models/argmax_2_float.model.cpp"
} // namespace argmax_2_float
TEST_F(NeuralnetworksHidlTest, argmax_2_float) {
    generated_tests::Execute(device,
                             argmax_2_float::createTestModel,
                             argmax_2_float::is_ignored,
                             argmax_2_float::examples);
}

namespace argmax_2_float_relaxed {
std::vector<MixedTypedExample> examples = {
// Generated argmax_2_float_relaxed test
#include "examples/argmax_2_float_relaxed.example.cpp"
};
// Generated model constructor
#include "vts_models/argmax_2_float_relaxed.model.cpp"
} // namespace argmax_2_float_relaxed
TEST_F(NeuralnetworksHidlTest, argmax_2_float_relaxed) {
    generated_tests::Execute(device,
                             argmax_2_float_relaxed::createTestModel,
                             argmax_2_float_relaxed::is_ignored,
                             argmax_2_float_relaxed::examples);
}

namespace argmax_2_int32 {
std::vector<MixedTypedExample> examples = {
// Generated argmax_2_int32 test
#include "examples/argmax_2_int32.example.cpp"
};
// Generated model constructor
#include "vts_models/argmax_2_int32.model.cpp"
} // namespace argmax_2_int32
TEST_F(NeuralnetworksHidlTest, argmax_2_int32) {
    generated_tests::Execute(device,
                             argmax_2_int32::createTestModel,
                             argmax_2_int32::is_ignored,
                             argmax_2_int32::examples);
}

namespace argmax_2_quant8 {
std::vector<MixedTypedExample> examples = {
// Generated argmax_2_quant8 test
#include "examples/argmax_2_quant8.example.cpp"
};
// Generated model constructor
#include "vts_models/argmax_2_quant8.model.cpp"
} // namespace argmax_2_quant8
TEST_F(NeuralnetworksHidlTest, argmax_2_quant8) {
    generated_tests::Execute(device,
                             argmax_2_quant8::createTestModel,
                             argmax_2_quant8::is_ignored,
                             argmax_2_quant8::examples);
}

namespace argmin_1_float {
std::vector<MixedTypedExample> examples = {
// Generated argmin_1_float test
#include "examples/argmin_1_float.example.cpp"
};
// Generated model constructor
#include "vts_models/argmin_1_float.model.cpp"
} // namespace argmin_1_float
TEST_F(NeuralnetworksHidlTest, argmin_1_float) {
    generated_tests::Execute(device,
                             argmin_1_float::createTestModel,
                             argmin_1_float::is_ignored,
                             argmin_1_float::examples);
}

namespace argmin_1_float_relaxed {
std::vector<MixedTypedExample> examples = {
// Generated argmin_1_float_relaxed test
#include "examples/argmin_1_float_relaxed.example.cpp"
};
// Generated model constructor
#include "vts_models/argmin_1_float_relaxed.model.cpp"
} // namespace argmin_1_float_relaxed
TEST_F(NeuralnetworksHidlTest, argmin_1_float_relaxed) {
    generated_tests::Execute(device,
                             argmin_1_float_relaxed::createTestModel,
                             argmin_1_float_relaxed::is_ignored,
                             argmin_1_float_relaxed::examples);
}

namespace argmin_1_int32 {
std::vector<MixedTypedExample> examples = {
// Generated argmin_1_int32 test
#include "examples/argmin_1_int32.example.cpp"
};
// Generated model constructor
#include "vts_models/argmin_1_int32.model.cpp"
} // namespace argmin_1_int32
TEST_F(NeuralnetworksHidlTest, argmin_1_int32) {
    generated_tests::Execute(device,
                             argmin_1_int32::createTestModel,
                             argmin_1_int32::is_ignored,
                             argmin_1_int32::examples);
}

namespace argmin_1_quant8 {
std::vector<MixedTypedExample> examples = {
// Generated argmin_1_quant8 test
#include "examples/argmin_1_quant8.example.cpp"
};
// Generated model constructor
#include "vts_models/argmin_1_quant8.model.cpp"
} // namespace argmin_1_quant8
TEST_F(NeuralnetworksHidlTest, argmin_1_quant8) {
    generated_tests::Execute(device,
                             argmin_1_quant8::createTestModel,
                             argmin_1_quant8::is_ignored,
                             argmin_1_quant8::examples);
}

namespace argmin_2_float {
std::vector<MixedTypedExample> examples = {
// Generated argmin_2_float test
#include "examples/argmin_2_float.example.cpp"
};
// Generated model constructor
#include "vts_models/argmin_2_float.model.cpp"
} // namespace argmin_2_float
TEST_F(NeuralnetworksHidlTest, argmin_2_float) {
    generated_tests::Execute(device,
                             argmin_2_float::createTestModel,
                             argmin_2_float::is_ignored,
                             argmin_2_float::examples);
}

namespace argmin_2_float_relaxed {
std::vector<MixedTypedExample> examples = {
// Generated argmin_2_float_relaxed test
#include "examples/argmin_2_float_relaxed.example.cpp"
};
// Generated model constructor
#include "vts_models/argmin_2_float_relaxed.model.cpp"
} // namespace argmin_2_float_relaxed
TEST_F(NeuralnetworksHidlTest, argmin_2_float_relaxed) {
    generated_tests::Execute(device,
                             argmin_2_float_relaxed::createTestModel,
                             argmin_2_float_relaxed::is_ignored,
                             argmin_2_float_relaxed::examples);
}

namespace argmin_2_int32 {
std::vector<MixedTypedExample> examples = {
// Generated argmin_2_int32 test
#include "examples/argmin_2_int32.example.cpp"
};
// Generated model constructor
#include "vts_models/argmin_2_int32.model.cpp"
} // namespace argmin_2_int32
TEST_F(NeuralnetworksHidlTest, argmin_2_int32) {
    generated_tests::Execute(device,
                             argmin_2_int32::createTestModel,
                             argmin_2_int32::is_ignored,
                             argmin_2_int32::examples);
}

namespace argmin_2_quant8 {
std::vector<MixedTypedExample> examples = {
// Generated argmin_2_quant8 test
#include "examples/argmin_2_quant8.example.cpp"
};
// Generated model constructor
#include "vts_models/argmin_2_quant8.model.cpp"
} // namespace argmin_2_quant8
TEST_F(NeuralnetworksHidlTest, argmin_2_quant8) {
    generated_tests::Execute(device,
                             argmin_2_quant8::createTestModel,
                             argmin_2_quant8::is_ignored,
                             argmin_2_quant8::examples);
}
